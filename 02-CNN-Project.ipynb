{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR_DIR = 'cifar-10-batches-py/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        cifar_dict = pickle.load(fo, encoding='bytes')\n",
    "    return cifar_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = ['batches.meta','data_batch_1','data_batch_2','data_batch_3','data_batch_4','data_batch_5','test_batch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = [0,1,2,3,4,5,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,direc in zip(all_data,dirs):\n",
    "    all_data[i] = unpickle(CIFAR_DIR+direc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_meta = all_data[0]\n",
    "data_batch1 = all_data[1]\n",
    "data_batch2 = all_data[2]\n",
    "data_batch3 = all_data[3]\n",
    "data_batch4 = all_data[4]\n",
    "data_batch5 = all_data[5]\n",
    "test_batch = all_data[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'num_cases_per_batch': 10000,\n",
       " b'label_names': [b'airplane',\n",
       "  b'automobile',\n",
       "  b'bird',\n",
       "  b'cat',\n",
       "  b'deer',\n",
       "  b'dog',\n",
       "  b'frog',\n",
       "  b'horse',\n",
       "  b'ship',\n",
       "  b'truck'],\n",
       " b'num_vis': 3072}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([b'batch_label', b'labels', b'data', b'filenames'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_batch1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# Cde to transform the X array!\n",
    "X = data_batch1[b\"data\"]\n",
    "X = X.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"uint8\")\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f511e50c828>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions for Dealing With Data.\n",
    "\n",
    "** Use the provided code below to help with dealing with grabbing the next batch once you've gotten ready to create the Graph Session. Can you break down how it works? **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(vec, vals=10):\n",
    "    '''\n",
    "    For use to one-hot encode the 10- possible labels\n",
    "    '''\n",
    "    n = len(vec)\n",
    "    out = np.zeros((n, vals))\n",
    "    out[range(n), vec] = 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CifarHelper():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.i = 0\n",
    "        \n",
    "        # Grabs a list of all the data batches for training\n",
    "        self.all_train_batches = [data_batch1,data_batch2,data_batch3,data_batch4,data_batch5]\n",
    "        # Grabs a list of all the test batches (really just one batch)\n",
    "        self.test_batch = [test_batch]\n",
    "        \n",
    "        # Intialize some empty variables for later on\n",
    "        self.training_images = None\n",
    "        self.training_labels = None\n",
    "        \n",
    "        self.test_images = None\n",
    "        self.test_labels = None\n",
    "    \n",
    "    def set_up_images(self):\n",
    "        \n",
    "        print(\"Setting Up Training Images and Labels\")\n",
    "        \n",
    "        # Vertically stacks the training images\n",
    "        self.training_images = np.vstack([d[b\"data\"] for d in self.all_train_batches])\n",
    "        train_len = len(self.training_images)\n",
    "        \n",
    "        # Reshapes and normalizes training images\n",
    "        self.training_images = self.training_images.reshape(train_len,3,32,32).transpose(0,2,3,1)/255\n",
    "        # One hot Encodes the training labels (e.g. [0,0,0,1,0,0,0,0,0,0])\n",
    "        self.training_labels = one_hot_encode(np.hstack([d[b\"labels\"] for d in self.all_train_batches]), 10)\n",
    "        \n",
    "        print(\"Setting Up Test Images and Labels\")\n",
    "        \n",
    "        # Vertically stacks the test images\n",
    "        self.test_images = np.vstack([d[b\"data\"] for d in self.test_batch])\n",
    "        test_len = len(self.test_images)\n",
    "        \n",
    "        # Reshapes and normalizes test images\n",
    "        self.test_images = self.test_images.reshape(test_len,3,32,32).transpose(0,2,3,1)/255\n",
    "        # One hot Encodes the test labels (e.g. [0,0,0,1,0,0,0,0,0,0])\n",
    "        self.test_labels = one_hot_encode(np.hstack([d[b\"labels\"] for d in self.test_batch]), 10)\n",
    "\n",
    "        \n",
    "    def next_batch(self, batch_size):\n",
    "        # Note that the 100 dimension in the reshape call is set by an assumed batch size of 100\n",
    "        x = self.training_images[self.i:self.i+batch_size].reshape(100,32,32,3)\n",
    "        y = self.training_labels[self.i:self.i+batch_size]\n",
    "        self.i = (self.i + batch_size) % len(self.training_images)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** How to use the above code: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting Up Training Images and Labels\n",
      "Setting Up Test Images and Labels\n"
     ]
    }
   ],
   "source": [
    "# Before Your tf.Session run these two lines\n",
    "ch = CifarHelper()\n",
    "ch.set_up_images()\n",
    "\n",
    "# During your session to grab the next batch use this line\n",
    "# (Just like we did for mnist.train.next_batch)\n",
    "# batch = ch.next_batch(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Model\n",
    "\n",
    "** Import tensorflow **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashish/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ashish/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ashish/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ashish/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ashish/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ashish/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/ashish/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ashish/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ashish/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ashish/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ashish/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ashish/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create 2 placeholders, x and y_true. Their shapes should be: **\n",
    "\n",
    "* x shape = [None,32,32,3]\n",
    "* y_true shape = [None,10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None,32,32,3])\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create one more placeholder called hold_prob. No need for shape here. This placeholder will just hold a single probability for the dropout. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions\n",
    "\n",
    "** Grab the helper functions from MNIST with CNN (or recreate them here yourself for a hard challenge!). You'll need: **\n",
    "\n",
    "* init_weights\n",
    "* init_bias\n",
    "* conv2d\n",
    "* max_pool_2by2\n",
    "* convolutional_layer\n",
    "* normal_full_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER\n",
    "\n",
    "# INIT WEIGHTS\n",
    "\n",
    "def init_weights(shape):\n",
    "    init_random_dist = tf.truncated_normal(shape,stddev=0.1)\n",
    "    return tf.Variable(init_random_dist)\n",
    "\n",
    "\n",
    "# INIT BIAS\n",
    "\n",
    "def init_bias(shape):\n",
    "    init_bias_vals = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(init_bias_vals)\n",
    "\n",
    "\n",
    "\n",
    "# CONV2D\n",
    "\n",
    "def conv2d(x,W):\n",
    "    # x --> [batch, H, W, Channels]\n",
    "    # W --> [filter H, filter W, Channels IN, Channels OUT]\n",
    "    \n",
    "    return tf.nn.conv2d(x,W,strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "\n",
    "\n",
    "# POOLING\n",
    "\n",
    "def max_pool_2by2(x):\n",
    "    # x --> [batch,h,w,c]\n",
    "    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "\n",
    "# Convolutional Layer\n",
    "\n",
    "def convolutional_layer(input_x,shape):\n",
    "    W = init_weights(shape)\n",
    "    b = init_bias([shape[3]])\n",
    "    return tf.nn.relu(conv2d(input_x,W)+b)\n",
    "    \n",
    "\n",
    "# Normal (Fully Connected Layer)\n",
    "\n",
    "def normal_full_layer(input_layer, size):\n",
    "    input_size = int(input_layer.get_shape()[1])\n",
    "    W = init_weights([input_size,size])\n",
    "    b = init_bias([size])\n",
    "    return tf.matmul(input_layer, W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Layers\n",
    "\n",
    "** Create a convolutional layer and a pooling layer as we did for MNIST. **\n",
    "** Its up to you what the 2d size of the convolution should be, but the last two digits need to be 3 and 32 because of the 3 color channels and 32 pixels. So for example you could use:**\n",
    "\n",
    "        convo_1 = convolutional_layer(x,shape=[4,4,3,32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_1 = convolutional_layer(x,shape=[4,4,3,32])\n",
    "convo_1_pooling = max_pool_2by2(convo_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create the next convolutional and pooling layers.  The last two dimensions of the convo_2 layer should be 32,64 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_2 = convolutional_layer(convo_1_pooling,shape=[4,4,32,64])\n",
    "convo_2_pooling = max_pool_2by2(convo_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Now create a flattened layer by reshaping the pooling layer into [-1,8 \\* 8 \\* 64] or [-1,4096] **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8*8*64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_2_flat = tf.reshape(convo_2_pooling,[-1,8*8*64])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create a new full layer using the normal_full_layer function and passing in your flattend convolutional 2 layer with size=1024. (You could also choose to reduce this to something like 512)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_layer_1 = tf.nn.relu(normal_full_layer(convo_2_flat,1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Now create the dropout layer with tf.nn.dropout, remember to pass in your hold_prob placeholder. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-24-3d508c605143>:4: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# DROPOUT\n",
    "\n",
    "hold_prob = tf.placeholder(tf.float32)\n",
    "full_one_dropout = tf.nn.dropout(full_layer_1, keep_prob=hold_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Finally set the output to y_pred by passing in the dropout layer into the normal_full_layer function. The size should be 10 because of the 10 possible labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = normal_full_layer(full_one_dropout,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-26-e0c07892321c>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true,logits=y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "train = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create a variable to intialize all the global tf variables. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Session\n",
    "\n",
    "** Perform the training and test print outs in a Tf session and run your model! **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently on step 0\n",
      "Accuracy is:\n",
      "0.1\n",
      "\n",
      "\n",
      "Currently on step 50\n",
      "Accuracy is:\n",
      "0.2527\n",
      "\n",
      "\n",
      "Currently on step 100\n",
      "Accuracy is:\n",
      "0.3079\n",
      "\n",
      "\n",
      "Currently on step 150\n",
      "Accuracy is:\n",
      "0.3368\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    \n",
    "    for i in range(200):\n",
    "        \n",
    "        batch = ch.next_batch(100)\n",
    "        \n",
    "        sess.run(train,feed_dict={x:batch[0],y_true:batch[1],hold_prob:0.5})\n",
    "        \n",
    "        # PRINT OUT A MESSAGE EVERY 100 STEPS\n",
    "        if i%50 == 0:\n",
    "            \n",
    "            print('Currently on step {}'.format(i))\n",
    "            print('Accuracy is:')\n",
    "            # Test the Train Model\n",
    "            matches = tf.equal(tf.argmax(y_pred,1),tf.argmax(y_true,1))\n",
    "\n",
    "            acc = tf.reduce_mean(tf.cast(matches,tf.float32))\n",
    "\n",
    "            print(sess.run(acc,feed_dict={x: ch.test_images,y_true: ch.test_labels,hold_prob:1.0}))\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
